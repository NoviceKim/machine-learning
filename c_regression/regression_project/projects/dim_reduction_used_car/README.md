### 주제: CarDekho 사이트에 올라온 중고차 가격 회귀 예측
- CarDekho는 인도의 중고차 관련 웹 사이트

<img src='../../images/cardekho.png' width='700px'>

---

#### Features (총 65개)


#### Targets
- listed_price: 판매 사이트에 제시된 가격

---

### 데이터 전처리

#### 결측치 조정
- 결측치 비율이 10%(3700개) 미만인 컬럼들은 결측치 삭제
- 10% 이상이면 대체(평균 or 중간값 or 최빈값)

- 현재 10% 이상의 결측치가 발견된 컬럼은 Drive Type과 Fuel Suppy System을 제외하고 모두 수치형

- 순서
> 1. 결측치 10% 미만 컬럼 결측치 삭제
> 2. Drive Type, Fuel Suppy System 결측치 조정
> 3. 결측치 10% 이상 컬럼 결측치 조정
> 4. 레이블 인코딩


이후 중복 삭제

<img src='../../images/dr01.png'>

#### 레이블 인코딩
- 문자열 feature들은 전부 레이블 인코딩


#### 표준화 후 이상치 제거


타겟 값이 200만 이상인 데이터 제거 후 인덱스 초기화



로그 변환 전후의 왜도 비교 결과, 변환 후 왜도가 낮아진 것을 확인
따라서 타겟 값에 로그를 취한 후 이후 과정 진행


---

### 1st Cycle - 차원 축소 없이 선형 회귀
- PCA 차원 축소 후 결과와 비교 분석




#### 1st Cycle - 차원 축소 없이 선형 회귀한 결과
- train 데이터와 test 데이터의 R2와 오차가 큰 차이를 보이지 않음
- 따라서 현재 모델에는 과적합이 발생하지 않은 것으로 추정


---

### 1st Cycle - 차원 축소
- 차원 축소 이전에도 만족스러운 결과를 보였지만,  
  학습에 사용된 feature의 개수가 많기 때문에 모델의 계산 효율에 악영향을 줄 수 있음
- 따라서 표현력 손실을 감수하더라도 차원 축소를 통해 계산 효율을 향상
- 현재 타겟이 연속형 데이터이기 때문에 차원 축소는 PCA 방식으로만 진행


#### 1st Cycle - 2차원으로 차원 축소



#### 1st Cycle - 5차원으로 차원 축소



#### 1st Cycle - 8차원으로 차원 축소


---

#### 1st Cycle - PCA 방식으로 차원 축소 후 Sklearn 선형 회귀 모델 학습 결과
- 차원 수를 8로 늘렸지만, R2는 0.5 미만으로  
  여전히 차원 축소 이전에 비해 심각하게 감소한 경향을 보임
- Pytorch로 차원 축소 이후 데이터 세트 학습 후, 위 과정에서 사용한 Sklearn과의 결과 비교

---

### 1st Cycle - Pytorch를 이용한 선형 회귀
- 데이터 세트는 위 과정으로 만들어진 pca_train_df와 pca_test_df 사용

---

#### 1st Cycle - 학습 결과
- 차원 축소 시, 차원 축소 이전에 비해 R2가 심각하게 감소하는 현상 발생
- 피드백 결과, 이는 차원 축소 이전 target과의 연관성이 낮은 feature들을 제거하지 않아서 생긴 문제라는 것을 알게 됨
- 따라서 다음 사이클에서는 target과의 연관성이 낮았던 feature들을 제거한 다음 학습

---

### 2nd Cycle - 데이터 전처리
- target과의 상관관계가 0.5 이하인 컬럼들을 전부 제거한 다음, 차원 축소 유무에 따른 학습 결과 비교

---

### 2nd Cycle - 차원 축소 없이 선형 회귀
- PCA 차원 축소 후 결과와 비교 분석


#### 2nd Cycle - 차원 축소 없이 선형 회귀한 결과
- 이전 사이클과 마찬가지로, train 데이터와 test 데이터의 R2와 오차가 큰 차이를 보이지 않음
- 따라서 현재 모델에는 과적합이 발생하지 않은 것으로 추정되며,  
  R2는 약 0.82 정도로 우수한 성능을 보임

---

### 2nd Cycle - 다항 회귀 모델로 회귀
- 별도의 차원 축소 없이 현재 데이터 세트 그대로 사용하여 Polynomial로 다항 회귀 진행
- 만약 이 과정과 트리 모델 학습 결과가 선형 모델에 비해 아쉬운 결과를 보인다면,  
  처음 방식대로 pre_c_df의 차원 축소를 통한 학습도 고려



#### 2nd Cycle - 다항 회귀 모델 학습 결과
- 회귀선의 차수를 6차까지 올려본 결과, 차수가 올라갈 수록 모델의 성능 역시 향상됨
- 다만, 회귀선의 차수가 5차를 넘어갔을 때부터 test 데이터 예측 결과가  
  train 데이터에 비해 낮아진 현상 역시 발견되었고, 이는 해당 시점부터 과적합 경향이 생긴 것으로 추정

---

### 2nd Cycle - 비선형 트리 모델로 회귀
- Decision Tree, Random Forest, Gradient Boosting, XGB, LightGBM 모델로 학습 후 각 모델의 결과 비교
- 위 과정으로 생성한 poly_features와 병행하지 않고, 원래의 features로 데이터 분할


#### 2nd Cycle - 비선형 모델 회귀 결과
- 현재 test 데이터에 대한 예측 성능이 가장 우수한 것은 XGB 모델로, 약 0.87 정도의 R2 Score를 기록함

- train과 test 데이터의 학습 결과에서 가장 적은 차이를 보인 것은 Gradient Boosting 모델로,  
  test 데이터 예측 결과의 R2는 이번에 사용한 모델 중 가장 낮은 약 0.85를 기록함

---

#### 2nd Cycle - 학습 결과
- 상관관계가 낮은 feature들을 제거함으로서 우수한 지표를 가진 모델이 만들어졌지만,  
  전처리 과정에서 중요한 feature들이 다수 소실됨
- 따라서 다음 사이클에서는 소실되었던 feature들 중 중요한 feature들을 하나씩 추가,  
  화이트 노이즈(편향)를 발생시켜 R2를 0.8 근처로 조정하는 것을 목표로 할 것

---

### 3rd Cycle - 데이터 전처리
- 이전 사이클에서 소실된 feature 중 일부를 복구

- 복구할 feature의 기준
> - 기존 또는 추가할 feature들과 의미가 중첩되지 않는 feature
> - 그 외, 중고차 가격 분석에 필요할 것이라 생각되는 feature

- 이 과정 이후, 차원 수가 8개 이상이 되면 PCA 방식으로 차원 축소 실행
> - 첫 사이클에 비해 feature 수가 많이 줄어든 상태이기 때문에 차원 축소 전후의 R2는 큰 변동이 없을 것으로 기대

---

### 3rd Cycle - 복구할 feature들
- 상관관계와 feature의 의미를 검토하여, pre_c_df에서 가져와 복구할 feature 7개를 선정
> - Cargo Volume: 차량 내 적재 공간
> - Top Speed: 최고 속도 (km/h)
> - transmission: 변속기 종류 (자동, 수동 등)
> - owner_type: 차량의 이전 소유주 수
> - fuel: 연료 (휘발, 경유, 천연가스 등)
> - Valves per Cylinder: 엔진 내 실린더 하나 당 밸브 수
> - utype: 판매자 유형 (딜러 / 개인)

- 위 feature들을 하나씩 추가, 이전 사이클에서 가장 우수한 결과를 보인 트리 모델로 학습시켜 결과의 변화 추이 분석

---

### 최종 학습 결과
- feature 복구 후 feature(차원) 수가 7개 이상이 되었을 때부터 차원 축소를 실행한 결과  
  마지막 utype까지 추가 한 뒤 3차원으로 차원 축소 했을 때,  
  train과 test 데이터 사이의 R2 Score 차이는 미미했으며, 오차는 거의 차이가 나지 않았다.

- 다만 이 때 test 데이터의 R2 Score는 약 0.74로,  
  feature 복구 이전의 R2 Score였던 0.85에 비해 상당히 낮아진 것이 확인되었다.













