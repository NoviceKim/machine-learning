회귀 프로젝트

총 4개 이상
- 회귀 3개
1. 선형 데이터
2. 비선형 데이터
3. 고차원 데이터(차원 축소)

- 분류 1개
고차원 데이터(차원 축소), Logistic Regression


* 과적합 검증하기
train 데이터 한 번 더 분리해서 학습 (validation 데이터)
test 데이터 학습 결과랑 R2 차이 크면 과적합 발생한 것
→ 과적합이 발생한 모델은 새로운 데이터에 대한 예측을 제대로 하지 못하기 때문

이 경우 test랑 validation 데이터의 R2 Score의 중간 정도로 R2 조정하기
ex) test 0.8, validation 0.6이면 R2 0.7 정도를 목표로 할 것

- 만약 R2 차이가 0.1 이하 정도로 크지 않으면 추가 전처리 필요 없음
→ test 데이터에서 R2 0.9가 뜨더라도 validation에서도 비슷하게 나오면 그냥 좋은 모델인 것


- 또 다른 방법
train 데이터 예측하고 y = x 그래프와 분포가 어느 정도 떨어졌는지 확인
만약 여기서 y = x 그래프의 형태와 너무나도 동떨어져 있다면 데이터 전처리부터 다시 할 것

y = x 그래프와 분포 형태가 어느 정도 일치한다면 같은 모델로 test 데이터 예측 후 시각화
test 데이터 시각화 결과가 train과 매우 다르다면 과적합
→ 과적합이 발생한 모델은 새로운 데이터에 대한 예측 성능이 떨어지기 때문

이 때, 아래의 Pytorch로 넘어갈 것
→ epoch 조정 및 규제 부여가 목적


- Pytorch 사용하는 이유?
Pytorch 사용 시 epochs 만큼의 반복을 통해 R2 이외에도 loss와 MSE를 얻을 수 있음

이를 이용해서 train 데이터와 validation 데이터를 학습시킨 다음
각 데이터의 epoch 별 loss 값을 산출, 이를 시각화하여 loss 차이가 벌어지는 지점이 과적합 지점

이로서 과적합이 발생하기 시작하는 지점에 규제를 걸어줌으로서 적절한 모델 학습이 가능하다


ex)
# train과 validation의 loss 값을 담을 파이썬 list 선언
train_loss = []
val_loss = []

~ for Epoch in Epochs 반복문 ~
train_loss(또는 val_loss).append(loss.item())

→ 여기까지 하면 train과 validation의 epoch n회마다의 loss가 담긴 list가 각각 만들어질 것


plt.plot(x=epochs, y=train_loss)
plt.plot(x=epochs, y=val_loss)
plt.show()

위 코드로 결과 시각화해서 두 그래프의 차이가 벌어지는 시점이 과적합 발생지점
이런 현상을 발견한 다음에야 epoch 조정하거나,
규제(Ridge, LASSO)를 걸어서 과적합 발생 시점에 학습을 종료하게 하는 것








